Лектор -- Олег Геннадьевич

*Лекция υ*

**Замечание (к теореме Бернулли)**
    Разложим бином (px + q)^n по формуле Ньютона
    (px + q)^n = Σ( С(n, m) (px)^m q^n-m : m = 0, n ) = Σ( (С(n, m) p^m q^n-m) x^m : m = 0, n ) =
    = Σ( P_n(m) x^m : m = 0, n )
    Поэтому совокупность вероятностей {P_n(m) : m = 0, n} называется биномиальным распределением

**Задача**
    Игральную кость бросают 7 раз. Какова вероятность того, что шестерка выпадет ровно три раза?
**Решение**
    n = 7; p = 1/6; q = 5/6; m = 3
    P_7(3) = C(7, 3) (1/6)^3 (5/6)^7-3 = 35 * 5^4 / 6^7

## Параграф 7. Полиномиальное распределение
Пусть производится n независимых испытаний, в каждом из которых происходит одно и только одно из событий
A_1, A_2, ... A_k
Таким образом, исходы A_1, A_2, ... A_k образуют полную группу попарно несовместных событий.
Пусть P(A_i) = p_i, где i = 1 .. k. Тогда
p_1 + p_2 + ... + p_k = 1
P_n(m_1, ... m_k)
Вероятность того, что в n независимых испытаниях
событие А_1 произойдет m_1 раз
событие А_2 произойдет m_2 раз
...
событие А_k произойдет m_k раз
где m_1 + ... + m_k = n
Рассуждая по аналогии с формулой Бернулли, можно доказать, что
P_n(m_1, ... m_k) = n! / (m_1! m_2! ... m_k!) * p_1^m1 * ... p_k^m_k

В частности, для k = 2 получаем обычное биномиальное распределение

Можно показать, что вероятность P_n(m_1, ... m_k) совпадает с коэффициентом при x_1^m_1 * ... x_k^m_k в разложении (p_1 x_1 + ... p_k x_k)^n по степеням

Поэтому совокупность вероятностей {P_n(m_1, ... m_k)} называют полиномиальным распределением

**Задача**
    Круглая мишень с четырьмя областями
            ----------------------
           /                      \ 
          /    ----------------    \ 
         /    /                \    \ 
        /    /     --------     \    \ 
       /    /     /   _    \     \    \ 
      /    /     /   / \    \     \    \ 
     (    (     (   ( I ) II ) III ) IV )
      \    \     \   \ /    /     /    /
       \    \     \   -    /     /    /
        \    \     --------     /    /
         \    \                /    /
          \    ----------------    /
           \                      /
            ----------------------
    Попадает с вероятностями
    I -- 0.2
    II -- 0.3
    III -- 0.4
    IV -- 0.1
    Какова вероятность, что стрелок из десяти выстрелов попадет
    в I -- 5 раз
    в II -- 2 раза
    в III -- 2 раза
    в IV -- 1 раз
**Решение**
    P_10(5, 2, 2, 1) = 10! / (5! * 2! * 2! * 1!) * 0.2^5 * 0.3^2 * 0.4^2 * 0.1

### Наивероятнейшее число появления события в независимых испытаниях
Пусть производится n независимых испытаний, в каждом из которых вероятность появления события А равна p
Тогда по формуле Бернулли
P_n(m) = C(n, m) p^m q^n-m

Зафиксируем числа n и p
{P_n(m) : m = 0, n}
Среди этих n+1 чисел имеется самое большое, при m = μ
**Определение**
    Число μ называется наивероятнейшим числом наступлений события А в n независимых испытаниях, если вероятность того, что событие А произойдет μ раз не меньше вероятности всех других исходов испытаний

Таким образом, число μ является точкой максимума функции P_n(m)

*Найдем формулу для μ*. Для этого найдем промежутки возрастания и убывания функции P_n(m)
    P_n(m + 1) / P_n(m) = C(n, m+1) / C(n, m) * p/q = n-m / m+1 * p/q
    P_n(m + 1) / P_n(m) >= 1 **<=>** n-m / m+1 * p/q >= 1
Итак,
    P_n(m+1) >= P_n(m) **<=>** m <= np - q

Крестики -- это отмеченные точки. Образуют график P_n(m)
^
|
|
|
|              x
|           x
|        x        x
|     x
|                    x
|  x
x
|
+--.--.--.--.--.--.--.------->
               μ     n        m
Т.к. μ -- точка максимума функции P_n(m), то
    P_n(μ - 1) <= P_n(μ) и P_n(μ + 1) <= P_n(μ)
    μ <= np + p и μ >= np - q
    np - q <= μ <= np + p
Отрезок [ np - q, np + p ] имеет длину, равную 1
Если np - q не целое, то отрезок содержит только одно значение
Иначе два значения -- np - q и np + p

**Задача**
    Производится 50 независимых испытаний. Вероятность наступления события А в каждом из них равна 1/3. Найти наивероятнейшее число наступлений события А.
**Решение**
    n = 50; p = 1/3; q = 2/3; μ - ?
    50 * 1/3 - 2/3 <= μ <= 50 * 1/3 + 1/3
    16 <= μ <= 17
    Ответ: μ = 16 и μ = 17
## Параграф 9. Локальная теорема Муавра-Лапласа
Рассмотрим формулу Бернулли.
    P_n(m) = C(n, m) p^m q^n-m
    Если числа n и m велики, то непосредственные вычисления по формуле Бернулли становятся сложными.
    Поэтому возникла необходимость в приближенной формуле для P_n(m)
**Теорема 1 (Локальная теорема Муавра-Лапласа)**
    Если вероятность наступления события А в n независимых испытаниях постоянно и равна p (0 < p < 1),
    то вероятность P_n(m) удовлетворяет при n -> INF
.
       sqrt(npq) P_n(m)
    -----------------------      -> 1
     1/sqrt(2π) e^(-x^2/2)
.
    равномерно для всех m, для которых
.
          m - np
    x = -----------
         sqrt(npq)
.
*Без доказательства*

Из данной теоремы следует, что при достаточно больших n выполняется приближенное равенство

   sqrt(npq) P_n(m)                 m - np
----------------------- ~= 1, x = -----------
 1/sqrt(2π) e^(-x^2/2)             sqrt(npq)

.                 e^(-x^2/2)
(2)  P_n ~= ----------------------
.            sqrt(npq) 1/sqrt(2π)

φ(x) = 1/sqrt(2π) e^(-x^2/2) -- функция **нормального распределения**
φ(x) является неотрицательной, непрерывной, четной

Для этой функции имеются подробные таблицы, составленные для положительных значений

Перепишем формулу (2) в виде
.             1                     m - np
P_n(m) ~= ---------- * φ(x), x = -----------
.         sqrt(npq)                sqrt(npq)

*Лекция υ + 1*

 Локальную формулу Муавра-Лапласа целесообразно применять, когда n велико (n >= 100), а p не близко к нулю и не близко к единице.

 **Комментарий**
    ^  P_n(m)
    |
    |
    |
    |              x
    |           x
    |        x        x
    |     x
    |                    x
    |  x
    x
    |
    +--.--.--.--.--.--.--.------->
                   μ    n        m
    (рис.1)
    [График нормального распределения] (рис.2)
    Идея Муавра-Лапласа в том, чтобы заменить ломаную на рис.1 гладкой кривой на рис.2
    И тем самым вместо вычисления P_n(m) вычислять формулу φ(x) с учетом 1/sqrt(npq)

## Параграф 10. Интегральная теорема Муавра-Лапласа
Рассмотрим  функцию.
            1            x
Φ(x) = ---------- * integrate e^(-t^2 / 2) dt             (1)
        sqrt(2π)         0
Функция Φ называется функцией Лапласа. Из равенства 1 следует, что эта функция непрерывная, строго возрастающая и нечетная.

lim Φ(x) = 1/2; lim Φ(x) = -1/2
x->+inf         x->-inf
.
.                     ^
.                     |
.                     |
.                  1/2|
.                 - - - - - - - - - - - - - - - - - - - - - - - -
.                     |                                x
.                     |                     x
.                     |               x
.                     |          x
.                     |      x
.                     |  x
.                     |x
----------------------x---------------------------->
.                    x|
.                  x  |
.              x      |
.          x          |
.   x                 |
.                     |
. - - - - - - - - - - - - -
.                     | -1/2
.                     |
.                     |
.                     |
.                     V

Для функции Лапласа есть таблицы для x in [0, 5]
Если x > 5, то полагают Φ(x) = 1/2

**Теорема 1. Интегральная теорема Муавра-Лапласа**
    Если вероятность наступления события А в n независимых испытаниях постоянна и равна p (0 < p < 1) и μ -- число наступлений события A в этих n испытаниях, то при n -> inf, равномерно относительно a и b (-inf <= a < b <= +inf) имеет место соотношение
             μ - np
    P(a <= ----------- < b) -> Φ(b) - Φ(a)
            sqrt(npq)
**Без доказательства**

При достаточно больших n можно счтитать,
             μ - np
    P(a <= ----------- <= b) ~= Φ(b) - Φ(a)          (2)
            sqrt(npq)
### Применение интегральной теоремы
1. Пусть производится n независимых испытаний, в каждом из которых вероятность наступления события A равна p. Найдем вероятность того, что в этих n испытаниях событие A произойдет не менее m_1 раз и не более m_2 раз. Эта вероятность обозначается

    P_n(m_1, m_2) = P(m_1 <= μ <= m_2) = P(m1 - np <= μ - np <= m_2 - np) =
         m_1 - np        μ - np         m_2 - np          m_2 - np         m_1 - np
    = P(----------- <= ----------- <= -----------) ~= Φ(-----------) - Φ(-----------)
         sqrt(npq)      sqrt(npq)      sqrt(npq)         sqrt(npq)        sqrt(npq)

    P_n(m_1, m_2) = Φ(x_2) - Φ(x_1)
    где        m_1 - np            m_2 - np
        x_1 = ----------- ; x_2 = -----------
               sqrt(npq)           sqrt(npq)

2. Отклонение относительной частоты от постоянной вероятности
    Относительной частотой события A называется отношение числа опытов, в которых событие A произошло, к общему число фактически произведенных испытаний.
    W(A) = m/n,
    n -- число фактически произведенных испытаний
    m -- число наступлений события A

    *Замечание!* Вероятность события вычисляется теоретически, а относительная частота всегда вычисляется на практике в результате проведения испытаний.

Пусть производится n независимых испытаний, причем вероятность появления события A в каждом из этих испытаний равна p. Найдем вероятность того, что в этих испытаниях относительная частота m/n отклонится от вероятности p по модулю не больше чем на ε.
                                                          m - np
P( |m/n - p| <= ε ) = P( -ε <= m/n - p <= ε ) = P( -ε <= -------- <= ε) =
                                                            n
                             m - np
= P( -ε * sqrt(n / pq) <= ----------- <= ε * sqrt(n / pq)) ~= Φ( ε sqrt(n / pq) ) - Φ( -ε sqrt(n / pq) ) = 2Φ( ε sqrt(n / pq) )
                           sqrt(npq)

## Параграф 11. Формула Пуассона
Локальная формула Муавра-Лапласа работает тем хуже, чем больше вероятность p отличается от 1/2. При малых p эта формула вообще неприменима.
Поэтому возникла необходимость в нахождении приближенной формулы, которая подходила бы для больших n и малых p, то есть для массовых, но редких событий.

Пусть производится n независимых испытаний, в каждом из которых вероятность наступления события A постоянна и равна p. Будем считать, что n велико, а p мало. Положим λ = np.
По формуле Бернулли
                              n(n-1)...(n-m+1)
P_n(m) = C(n, m) p^m q^n-m = ------------------ * (λ / n)^m * (1 - λ/n)^n-m =
                                    m!

= (λ^m / m!) * n/n * ... * ((n - m + 1) / n) * (1 - λ/n)^n-m = (λ^m / m!) * (1 - 1/n)(1 - 2/n)...(1 - m-1/n) (1 - λ/n)^n (1 - λ/n)^-m

Так как n велико,
P_n(m) ~= lim P_n(m)
          n->inf

Перейдем к пределу при n -> inf, причем λ const

P_n(m) ~= lim     ( (λ^m / m!) * (1 - 1/n)(1 - 2/n)...(1 - m-1/n) (1 - λ/n)^n (1 - λ/n)^-m ) =
          n->inf
= λ^m / m! lim    (1 - λ/n)^n = λ^m / m! lim    (  ( 1 - λ/n )^-n/λ  )^-λ =
           n->inf                        n->inf
Применяя второй замечательный предел, получим

P_n(m) ~= λ^m / m! e^-λ, где λ = np          (1), **Формула Пуассона**

**Замечание**
Формулу Пуассона целесообразно применять, когда
n >= 100, p ~ 0.01 лучше меньше

**Задача**
    Станция скорой помощи обслуживает 10_000 человек. Вероятность того, что человек вызовет скорую в течение суток 0.002. Какова вероятность того, что в течение суток поступит 15 вызовов
**Решение**
    n = 10_000; m =15; p =0.002
    λ = np = 20
    P_10000(15) ~= 20^15 / 15! e^-20

**Лекция υ + 2**

## Параграф 12. Цепи Маркова
Непосредстваенным обобщением схемы независимых испытаний Бернулли является схема цепей Маркова.

Пусть производится последовательность испытаний, в каждом из которых происходит одно и только одно из k событий. Эти события образуют полную группу попарно несовместных событий.
    A_1^(s), A_2^(s), ... A_n^(s)
Верхний индекс s означает номер испытаний.

**Определение 1**
    Последовательность испытаний называется цепью Маркова, если условная вероятность
    P(A_j^(s+1) / A_i^(s))
    не зависит от результатов предшествующих испытаний.

**Определение 2**
    Цепь Маркова называется однородной, если вероятность P(A_j^(s+1) / A_i^(s)) не зависит от номера испытания s.
    В этом случае эту вероятность обозначают p_ij и называют вероятностью перехода или переходной вероятностью.

В теории однородных цепей Маркова обычно пользуются следующей терминологией:
Говорят о некоторой физической системе S, которая может находиться в одном и только одном из k возможных состояний
    A_1, A_2, ... A_k

В случайные моменты времени система переходит из одного состояния в другое. p_ij -- вероятность перехода системы из состояния A_i в состояние A_j. Марковское свойство заключается в том, что вероятность перехода из состояния A_i в состояние A_j не зависит от того, в каком состоянии система была ранее. *Грубо говоря, будущее состояние системы определяется ее текущим, настоящим состоянием и не зависит от прошлого.*

**Определение 3**
    Матрица, составленная из вероятностей перехода, называется *матрицей перехода* или *матрицей переходных вероятностей* и обозначается π_1.
          (p_11   p_12   ...     p_1k)
    π_1 = (p_21   p_22   ...     p_2k)
          (- - - - - - - - - - - - - )
          (p_k1   p_k2   ...     p_kk)

Из определения следует, что матрица π_1 обладаетс следующими свойствами:
1. 0 <= p_ij <= 1
2. Для любого i
    Σ(p_ij : j = k, 1) = 1
Матрица, элементы которой удовлетворяют условиям 1 и 2, называются *стохастическими*.

#### Пример 1. Случайное блуждание частицы с поглощением
-------|-------|-------|-------|-------|-------|-------|------->
       1                                               k
Частица перемещается вдоль отрезка [1, k], причем может находиться только в целочисленных точках. В случайные моменты времени частица испытывает толчок, в результате которого она может переместиться на одну единицу вправо с вероятностью p, либо на одну единицу влево с вероятностью q. Причем p + q = 1
В точках x = 1 и x = k расположений ПОГЛОЩАЮЩИЕ ЭКРАНЫ.
A_i -- частица находится в точке x = i; i = 1..k
Такое случайное блуждание частицы является примером цепи Маркова, поскольку
    p_ij = P(A_j / A_i)
Не зависит от того, где частица находилась ранее.
Составим матрицу переходов:
      (1000 ... 000)
π_1 = (q0p0 ... 000)
      (0q0p ... 000)
      (- - - - - - )
      (0000 ... q0p)
      (0000 ... 001)

#### Пример 2. Случайное блуждание частицы с отражением
Условие такое же, как в предыдущем примере, только в точках x = 1 и x = k расположены ОТРАЖАЮЩИЕ ЭКРАНЫ.
В качестве упражнения составить π_1 самостоятельно
      (0100 ... 000)
π_1 = (q0p0 ... 000)
      (0q0p ... 000)
      (- - - - - - )
      (0000 ... q0p)
      (0000 ... 010)
--------------------------------------------------

Для наглядного представления цепей Маркова используют графы. При этом возможные состояния системы обозначаются вершинами графа, а переходы -- ребрами.

Матрица переходов не полностью характеризует цепь Маркова, поскольку не учитывает первоначальное распределения вероятностей. Обозначим через p_i вероятность того, что система находится в состоянии A_i в начальный момент времени. Числа p_1, p_2, ... p_k называются начальными вероятностями.
(p_1 + p_2 + ... + p_k = 1)
       _
Вектор p = (p_1, p_2, ..., p_k) называется начальным распределением вероятностей цепей Маркова.
       _
Вектор p и матрица π_1 полностью характеризуют цепь Маркова.
Обозначается через P_ij(n) вероятность перехода системы из состояния A_i в состояние A_j за n шагов.
      (P_11(n)   P_12(n)   ...     P_1k(n))
π_n = (P_21(n)   P_22(n)   ...     P_2k(n))
      (- - - - - - - - - - - - - - - - - -)
      (P_k1(n)   P_k2(n)   ...     P_kk(n))
В частности, P_ij(1) = p_ij
**Теорема 1**
    Справедливо следующее равенство:
              j
    P_ij(n) = Σ(P_ij(m) * P_lj(n - m)) *(1)*
             l=1
    Равенство *(1)* называется равенством Маркова
**Доказательство**
    B -- A_i в A_j за n шагов. H_l -- система переходит из A_i в A_j за m шагов, где l = 1..k
    P(H_l) = P_ij(m); P(B / H_l) = P_lj(n - m)
    По формуле полной вероятности
                                                         k
    P(B) = P_ij(n) = Σ(P(H_l) * P(B / H_l) : l = 1..k) = Σ(P_il(m) * P_lj(n - m))
                                                        l=1
    **QED**
Пусть n = 2.
          k                     k
P_ij(2) = Σ(P_il(1) P(lj(1))) = Σ(p_il p_lj)
         l=1                   l=1
Рассуждая по индукции, получим
π_2 = π_1 π_1 = π_1 ^2
+--------------+
| π_n = π_1 ^n |
+--------------+

Если известно рапределние вероятностей в текущий момент времени,
                                                                                 _
Чтобы найти распределения вероятностей в следующий момент времени (обозначим его p_1)
_     _
p_1 = p * π_1
Эта формула вытекает из Теоремы 1.

#### Задание 1
Может быть 4 состояния погоды:
- Ясно
- Переменная облачность
- Пасмурно
- Дождь

Если сегодня Ясно, то завтра будет
- Ясно с вероятностью 0.5
- Переменная облачность с вероятностью 0.3
- Пасмурно с вероятностью 0.1
- Дождь с вероятностью 0.1

Если сегодня Переменная облачность, то завтра будет
- Ясно с вероятностью 0.2
- Переменная облачность с вероятностью 0.4
- Пасмурно с вероятностью 0.3
- Дождь с вероятностью 0.1

Если сегодня Пасмурно, то завтра будет
- Ясно с вероятностью 0.3
- Переменная облачность с вероятностью 0.3
- Пасмурно с вероятностью 0.2
- Дождь с вероятностью 0.2

Если сегодня Дождь, то завтра будет
- Ясно с вероятностью 0.2
- Переменная облачность с вероятностью 0.3
- Пасмурно с вероятностью 0.4
- Дождь с вероятностью 0.1

      (.5 .3 .1 .1)
π_1 = (.2 .4 .3 .1)
      (.3 .3 .2 .2)
      (.2 .3 .4 .1)
      _
Пусть p = (1 0 0 0)
_     _
p_1 = p * π_1 = (.5 .3 .1 .1)

**Лекция υ + 3**

# Раздел 2. Случайные величины
## Параграф 1. Понятие случайной величины. Функция распредления случайной величины

Пусть Ω -- пространство элементарных исходов некоторого опыта
**Определение 1**
    Случайной величиной называется однозначная вещественная функция ξ(ω), определенная на пространстве элементарных событий Ω, :
    для любого x in *R* множество элементарных событий вида {ω: ξ(ω) < x} является событием

Так как множество {ω: ξ(ω) < x} является событием, то определена его вероятность P({ω: ξ(ω) < x}), которую будем обозначать P(ξ < x)

**Определение 2**
    Функция распределения СВ (случайно величины) ξ называется функция F_ξ(x), которая определяется на *R* равенством
    F_ξ(x) = P(ξ < x)

### Пример 1
Бросается игральная кость.
Ω = {ω_1, ... ω_6}, где ω_i -- выпала i-тая грань.
Определим функция ξ(ω) формулой ξ(ω_i) = i -- число выпавших очков. Очевидно, что эта функция является случайной величиной, ее возможные значения: 1, 2, 3, 4, 5, 6. В результате опыта функция принимает одно из своих возможных значений.

Найдем функцию распределения этой случайной величины
                     {
                     | 0, x <= 1
                     | 1/6, 1 < x <= 2
                     | 1/3, 2 < x <= 3
F_ξ(x) = P(ξ < x) = <  1/2, 3 < x <= 4
                     | 2/3, 4 < x <= 5
                     | 5/6, 5 < x <= 6
                     | 1, x > 6
                     {
 F_ξ(x) ^
        |
      1 |                                   oxxxxxx
        |
    5/6 |                             oxxxxxx
        |
    2/3 |                       oxxxxxx
        |
    1/2 |                 oxxxxxx
        |
    1/3 |           oxxxxxx
        |
    1/6 |     oxxxxxx
        |
        xxxxxxx-----.-----.-----.-----.-----.----->
       0      1     2     3     4     5     6     x

### Свойства
1) 0 <= F_ξ(x) <= 1 для всех x in *R*
Доказательство: из определения
2) Для любых a, b in *R* выполняется равенство
    P(a <= ξ < b) = F_ξ(b) - F_ξ(a)
Доказательство:
    F_ξ(b) - F_ξ(a) = P(ξ < b) - P(ξ < a) = P(ξ < a или a <= ξ < b) - P(ξ < a) =
    Применяя теорему сложения для несовместных событий, получим
    = P(ξ < a) + P(a <= ξ < b) - P(ξ < a) = P(a <= ξ < b)
    QED
3) Функция распределния является неубывающей
Доказательство:
    Для любых x1, x2 in *R*: x1 < x2
    По свойству (2)
    F_ξ(x2) - F_ξ(x1) = P(x1 <= ξ < x2) >= 0
    то есть
    F_ξ(x2) >= F_K(x1)
    QED
4) lim F_ξ(x) = 0, lim F_ξ(x) = 1
   x->INF          x->INF
Без доказательства
.
Используем обозначения
F_ξ(a - 0) = lim F_ξ(x) -- предел F_ξ(x) в точке a слева
             x->a-0
F_ξ(a + 0) = lim F_ξ(x) -- предел F_ξ(x) в точке a справа
             x->a+0
5) F_ξ(x) непрерывна слева, то есть
    F_ξ(x - 0) = F_ξ(x) для любого x in *R*
Доказательство:
.
    ------.------.------.------.------.------.------.------.------.------.------>
          x1     x2                ...                            x_n  **x**
    {x_n} A_n = {x_n <= ξ < x}, где n in *N*
.
    A_1 ) A_2 ) A_3 ) ... ) A_n ) ... и  \
    INF
     Π A_n = V _(невозможное событие)_
    n=1
    Тогда
    lim P(A_n) = P(V) = 0
    n->INF
.
    По свойству 2
    P(A_n) = P(x_n <= ξ < x) = F_ξ(x) - F_ξ(x_n)
    Тогда
    lim (F_ξ(x) - F_ξ(x_n)) = 0
    n->INF
    F_ξ(x) - F_ξ(x-0) = 0
    F_ξ(x-0) = F_ξ(x)
    QED
6) Пусть x_0 -- точка разрыва F_ξ(x). Тогда:
F_ξ(x_0 + 0) - F_ξ(x_0) = P(ξ = x_0)
то есть скачок функции распредления в точке x_0 равен вероятности того, что случайная величина ξ примет значение, равное x_0
Без доказательства.

**Замечание**
Если некоторая функция f(x) является неубывающей, непрерывной слева и при этом
lim f(x) = 1, lim f(x) = 0
x->+INF       x->-INF
То эта функция f(x) является функцие распределения некоторой случайной величины
Без доказательства.

**Определение 3**
Случайные величины ξ1 и ξ2 называются независимыми, если для любых x1, x2 in *R*
P(ξ1 < x1, ξ2 < x2) = P(ξ1 < x1) * P(ξ2 < x2)
**Пример**
    ξ1 = a = const
    ξ2 -- произвольная СВ
    ξ1 и ξ2 -- независимы


## Параграф 2. Дискретные случайные величины
**Определение 1**
    Случайная величина называется дискретной, если множество ее возможных значений конечно или счетно
**Определение 1**
    Законом распределения дискретной СВ называется перечень возможных ее значений, расположенных в порядке возрастания и соответствующих им вероятностей
Обычно закон распределения случайной величины задают в виде таблицы
    +------+------+------+------+------+------
  ξ |  x1  |  x2  |     ...     |  x_n |   ...
 ---+------+------+------+------+------+------
  P |  p1  |  p2  |     ...     |  p_n |   ...
    +------+------+------+------+------+------

Σ(p_k) = 1
k

F_ξ(x) = Σ(p_n)
     x_n < x

### Примеры дискретных случайных величин
##### Пример 1. Биномиальное распределение
Пусть производится n независимых испытаний, в каждом из которых вероятность наступления события A равна p.
Рассмотрим СВ ξ -- число наступлений событий A в n испытаниях.
Возможные значения СВ ξ: 0, 1, 2 ... n
P(ξ = m) = P_n(m) = C(n, m) p^m q^n-m
Составим закон распределения этой СВ.
    +-----------+-----------+-----------+-----------+--------------------+-----------+-----------+
  ξ |     0     |     1     |          ...          |     m              |   ...     |     n     |
 ---+-----------+-----------+-----------+-----------+--------------------+-----------+-----------+
  P |    q^n    | n p q^n-1 |          ...          |  C(n,m) p^m q^n-m  |   ...     |     p^n   |
    +-----------+-----------+-----------+-----------+--------------------+-----------+-----------+
.
                    {
                    { 0, x <= 0
                    {
F_ξ(x) = P(ξ < x) = {   Σ C(n, m) p^m q^n-m, 0 < x <=n
                    { m < x
                    {
                    { 1, x > n
                    {

 F_ξ(x) ^
        |
      1 |                             oxxxxxxxxxxxxxxxx
        |
        |                       oxxxxxx
        |
        |                 oxxxxxx
        |
        |           oxxxxxx
        |
        |     oxxxxxx
        |
        oxxxxxx
        |
 xxxxxxxx---------------------------------->
       0                              n    x

*Лекция υ + 4*

##### Пример 2. Распределение Пуассона
Говорят, что дискретная случайная величина ξ имеет распределние Пуассоона, если ее возможными значениями являются все целые неотрицательные числа (ξ = 0, 1, ... n, ...)
и вероятность того, что P(ξ = n) = λ^n / n! * e^-λ, где λ > 0
число λ называется параметром распределения
Составим закон распределения
    +-----------+-----------+-----------+-----------+--------------------+-----------
  ξ |     0     |     1     |          ...          |          n         |   ...
 ---+-----------+-----------+-----------+-----------+--------------------+-----------
  P |    p^-λ   |  λ e^-λ   |          ...          |  λ^n / n! * e^-λ   |   ...
    +-----------+-----------+-----------+-----------+--------------------+-----------
Заметим, что
INF               INF
 Σ P(ξ = n) = e^-λ Σ (λ^n / n!) = e^-λ e^λ = 1
n=0               n=0
.
                    { 0, x <= 0
F_ξ(x) = P(ξ < x) = {
                    {   Σ (λ^n / n! * e^-λ), x > 0
                    { n < x

Пусть производится последовательность испытаний, в каждом из которых вероятность наступления события A равна p. Испытания проводят до тех пор, пока не произойдет событие A.
Рассмотрим случайную величину ξ -- число произведенных испытаний
Возможными значениями слуйчайной величины ξ являются все натуральные числа (ξ = 1, 2 ... n, ...)
P(ξ = n) = p q^n-1, где q = 1 - p
Составим закон распределения:
    +-----------+-----------+-----------+-----------+--------------------+-----------
  ξ |     1     |     2     |          ...          |         n          |   ...
 ---+-----------+-----------+-----------+-----------+--------------------+-----------
  P |     p     |    p q    |          ...          |       p q^n-1      |   ...
    +-----------+-----------+-----------+-----------+--------------------+-----------
Заметим, что
INF          INF           INF
 Σ P(ξ = n) = Σ p q^n-1 = p Σ q^n-1 = p / 1-q = p/p = 1
n=1          n=1           n=1

P(ξ = n) = p q^n-1
Является геометрической прогрессией. Именно поэтому такое распределение называют геометрическим.
.
                    { 0, x <= 1
F_ξ(x) = P(ξ < x) = {
                    {   Σ ( p q^n-1 ), x > 1
                    { n < x

## Параграф 3. Непрерывные случайные величины
**Определение 1**
    Случайная величина ξ называется непрерывной, если существует такая неотрицательная интегрируемая функция p_ξ(x), что выполняется равенство
                  x
    F_ξ(x) = integrate p_ξ(t) dt
                -INF
    Функцию p_ξ(x) называют плотностью распределения вероятностей или просто плотностью распределения.

### Свойства плотности распределения
1. Условие нормировки. Для функции p_ξ(x) выполняется равенство
      +INF
    integrate p_ξ(t) dt = 1
      -INF
    **Доказательство**
      +INF                            +INF
    integrate p_ξ(t) dt =  lim     integrate p_ξ(t) dt =
      -INF                x->+INF     -INF

    =  lim F_ξ(x) = 1
      x->+INF
    по свойтству 4 из параграфа 1
    **QED**
2. p_ξ(x)
    'F_ξ = p_ξ(x)
   _^ это типа F', производная_
   **Доказательство**
   По свойству интеграла с переменным верхним пределом 😐
3. для любых a, b ∈ *R*
                        b
    P(a <= ξ < b) = integrate p_ξ(t) dt
                        a
    **Доказательство**
    P(a <= ξ < b) = по свойству 2 из параграфа 1
    = F_ξ(b) - F_ξ(a) =
          b                     a
    = integrate p_ξ(t) dt - integrate p_ξ(t) dt =
        -INF                  -INF
          b
    = integrate p_ξ(t) dt
          a
4. Вероятность того, что непрерывная случайная величина примет одно определенное значение равна нулю
    **Доказательство**
    Пусть x -- возможное значение СВ ξ.
    ------------.------------.------------>
                x           x+Δx
    P(ξ = x) = lim P(x <= ξ < x + Δx) =
              Δx->0

              x + Δx
    = lim   integrate p_ξ(t) dt = 0
     Δx->0      x
    **QED**

**Замечание**
    Из свойств 3 и 4 следует равенство:
    P(a <= ξ < b) = P(a <= ξ <= b) = P(a < ξ < b) = P(a < ξ <= b) =
          b
    = integrate p_ξ(t) dt
          a
    _знак ставь как хочешь 🤒_

## Равномерное распределение
Распределение непрерывной случайной величины называется **равномерным**, если его плотность задается формулой
.
         { 0, x < a
p_ξ(x) = { 1 / b-a, a <= x <= b
         { 0, x > b

 F_ξ(x) ^
        |
        |
        |
        |
1 / b-a |. . . . xxxxxxxxxxxxxxxxxxxxxxx
        |        .
        |                              .
        |        .
        |                              .
        |        .
        |                              .
        |        .
        |                              .
 xxxxxxxxxxxxxxxxo---------------------oxxxxxxxxxxxxxxxxx>
       0         a                     b                 x
.
    b
integrate p_ξ(x) dx = ...[списать] = 1
    a

Найдем функцию распределения
1) Если x < a, то
        vvvvvvvvvvv
        ----------x----a---------b----------->

             x                     x
F_ξ(x) = integrate p_ξ(t) dt = integrate 0 dt = 0
           -INF                  -INF
2) Если a <= x <= b, то
        vvvvvvvvvvvvvvvv
        ----------a----x---------b----------->
             x                     a                x                   x - a
F_ξ(x) = integrate p_ξ(t) dt = integrate 0 dt + integrate 1 / b-a dt = -------
           -INF                  -INF               a                   b - a
3) Если x > b, то
        vvvvvvvvvvvvvvvvvvvvvvvvvvvvv
        ----------a------------b----x------->
             x                     a                b                      b
F_ξ(x) = integrate p_ξ(t) dt = integrate 0 dt + integrate 1 / b-a dt + integrate 0 dt = 1
           -INF                  -INF               a                      a
         { 0, x < a
F_ξ(x) = { x-a / b-a, a <= x <= b
         { 1, x > b

 F_ξ(x) ^                                              
        |                                              
        |                                              
        |                                             
      1 | . . . . . . . . . . . . xxxxxxxxxxxxxxxxxx                               
        |                        x.                               
        |                       x                               
        |                      x  .                               
        |                     x                               
        |                    x    .                               
        |                   x                               
        |                  x      .                               
        |                 x                               
        |                x        .                               
    xxxxxxxxxxxxxxxxxxxxx------------------------->                               
       0                a         b               x                               

## Параграф 4. Математическое ожидание и его свойства
Поскольку нахждение функции распределения бывает затруднительным, используются другие, более простые характерстики случайной величины. Это так называемые числовые характеристики, среди которых главными являются **математическое ожидание** и **дисперсия**.
## Пункт 1. Определение и вероятностный смысл математического ожидания
**Определение 1**
   1) Пусть ξ -- дискретная случайная величина, принимающая конечное множество значений x1, x2, ... x_n с вероятностями p1, p2 ... p_n соответственно
   Математическим ожиданием этой случайной величины называется число
        n
   Mξ = Σ x_k p_k
       k=1
   2) Пусть ξ -- дискретная случайная величина, принимающая счетное множество значений x1, x2 ... x_n, ... с вероятностями p1, p2 ... p_n ...
   Математическим ожиданием этой случайной величины называется число
       INF
   Mξ = Σ x_k p_k, если ряд сходится абсолютно
       k=1
**Определение 2**
    Пусть ξ -- непрерывная СВ и p_ξ(x) -- ее плотность распределения. Математическим ожиданием этой случайной величины называется число
            +INF
    Mξ = integrate x p_ξ(x) dx, если интеграл сходится абсолютно
            -INF
    *Комментарий: в литературе вместо Mξ могут писать Eξ*

**Лекция 2024-10-29**

Выясним вероятностный смысл математического ожидания на примере дискретной
случайной величины с конечным множеством значений.

Пусть дискретная случайная величина ξ задана своим законом распределения:
     +---+-----------------------+
     | ξ | x1 | x2 |  ...   | xn |
     +---------------------------+
     | P | p1 | p2 |  ...   | pn |
     +---+-----------------------+

Предположим что проведено N испытаний, в результате которых значение x1 наблюдалось
m1 раз, значение x2 -- m2 раз, ..., значение xn -- mn раз, причем
      m
      Σ mk  =  N
     k=1

Найдем среднее значение случайной величины ξ:
     _      (  m       )             m
     ξ  =  (   Σ xk mk  )  /  N  =   Σ xk (mk / N)    (=)
            ( k=1      )            k=1
                                              ^^^^^^^^
                                          Относительная частота события xk
                                              из N событий.
    let wk = mk / N  -- относительная частота события { ξ = xk }
                m
           (=)  Σ xk wk
           k=1

Если N достаточно велико, то wk ~= pk, тогда:
         _        m             m
         ξ   =    Σ xk wk  ~=   Σ xk pk  =  Mξ
             k=1           k=1
               _            _
Таким образом, ξ = Mξ,  где ξ -- среднее арифметическое по ξ

Математическое ожидание случайной величины приближенно равно (тем точнее, чем
больше число испытаний) среднему арифметическому значению наблюдаемых значений
этой случайной величины.

### Примеры вычисления математического ожидания

(1) Биномиальное распределение

Пусть дискретная случайная величина ξ имеет биномиальное распределение. Её
возможные значения это 0, 1, ..., n, причем:
    P(ξ = m) = Cn^m p^m q^(n - m)

Найдем математическое ожидание:
                n                  n
    Mξ  =   Σ m P(ξ = m)  =    Σ m Cn^m p^m q^(n - m)  =
               m=0                m=1
                                    ^- !
                n
            =   Σ m (n! / m!(n-m)!) p^m q^(n - m)          =
               m=1
                n
            =   Σ (n! / (m - 1)!(n-m)!) p^m q^(n - m)      =
               m=1
                   n
            =  np  Σ ((n - 1)! / (m - 1)!(n-m)!) p^(m - 1) q^(n - m)  =
                  m=1
    Делаем замену:
                k = m - 1 (тогда m = k + 1)
                  n-1
            =  np  Σ ((n-1)! / k!(n-k-1)!) p^k q^(n-k-1)  =
                  k=0
                  n-1
            =  np  Σ C_(n-1)^k p^k q^(n-1-k)              =
                  k=0
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^
                     Бином Ньютона
            =  np (p + q) ^ (n - 1) = np 1^(n - 1)        = np
    Значит справедлива формула:
        Mξ = np


(2) Распределение Пуассона

Пусть дискретная случайная величина ξ имеет распределение Пуассона. Её возможные
значения: 0, 1, ..., n, ..., причем:
    P(ξ = n) = (λ^n / n!) * e^(-λ),  где λ > 0
              ∞              ∞
    Mξ =  Σ  n P(ξ=n) =  Σ  n (λ^n / n!) e^(-λ)  =
             n=0            n=1
                     ∞
           = e^(-λ)  Σ  (λ^n / (n - 1)!)             =
                    n=1
                        ∞
           = λ e^(-λ)   Σ  (λ^(n - 1) / (n - 1)!)    =
                       n=1
        Делаем замену
        k = n - 1 (тогда n = k + 1)
                        ∞
           = λ e^(-λ)   Σ  λ^k / k!                  =
                       k=0
                       ^^^^^^^^^^^  = e^λ из непры
           = λ e^(-λ) e^λ                            = λ

Итак,
    Mξ = λ


(3) Равномерное распределение
Пусть непрерывная случайная величина ξ имеет равномерное распределение, то есть
её плотность задается формулой:
                 { 0,                 x <  a
    p_ξ(x) = { 1 / (b - a),  a <= x <= b
                 { 0,            b <  x
           (               x              )
       (    F_ξ(x) = \int  p_ξ(t) dt  ) -- плотность берется отсюда
           (              -∞              )   (Непрерывные случайные величины)
           ∞
    Mξ = \int x p_ξ(x) dx  =
          -∞
                 a               b                       ∞
           =   \int x*0 dx  +  \int x 1 / (b-a) dx  +  \int x*0 dx =
                -∞               a                       b
                       b
       = 1/(b-a) \int x dx =   1/(b-a) * (b^2 - a^2) / 2  = (a + b) / 2
                       a

Итак,
    Mξ = (a + b) / 2



* Свойства математического ожидания

**Свойство 1**
    Математическое ожидание константы равно этой константе:
    MC = C
**Доказательство**
    Константу C можно рассматривать как случайную величину ξ, у
    которой единственное возможное значение C принимается с вероятностью
    равной 1.
        MC = Mξ = C * 1 = C

**Свойство 2**
    Константный множитель можно выносить за знак мат. ожидания, т.е:
        M(Cξ) = C * Mξ
**Доказательство**
    Доказательство проведем для дискретной случайной величины со счетным
    множеством значений (у нас ведь два определение для мат. ожидания, одно
    из них -- непрерывное). Пусть ξ задана своим законом распределения:
         +---+--------------------+-----+
         | ξ | x1 | x2 | ... | xn | ... |
         +------------------------+-----+
         | P | p1 | p2 | ... | pn | ... |
         +---+--------------------+-----+
              n
    M(Cξ)  =  Σ  (C * x)i pi
             i=1

Рассмотрим случайную величину C * ξ:

Возможные значения этой случайной величины:
    Cx1, Cx2, ..., Cxn, ...
    P(Cξ = Cxn) = P(ξ = xn) = pn
Таким образом, закон распределения случайной величины Cξ имеет вид:
.
     +---+--------------------+-----+
     |Cξ |Cx1 |Cx2 | ... |Cxn | ... |
     +------------------------+-----+
     | P | p1 | p2 | ... | pn | ... |
     +---+--------------------+-----+
                   ∞                ∞
    M(Cξ)  =   Σ C xn pn  =  C  Σ xn pn  =  C * Mξ
                  n=1              n=1

**Свойство 3**
    Математическое ожидание суммы любых двух случайных величин равно
    сумме их мат. ожиданий:
        M(ξ + Ω) = Mξ + MΩ
**Доказательство**
    Пусть случайные величины ξ и Ω заданы своими рядами распределения:
.
         +---+--------------------+-----+
         | ξ | x1 | x2 | ... | xn | ... |
         +------------------------+-----+
         | P | p1 | p2 | ... | pn | ... |
         +---+--------------------+-----+
.
         +---+--------------------+-----+
         | Ω | y1 | y2 | ... | yk | ... |
         +------------------------+-----+
         | P | q1 | q2 | ... | qk | ... |
         +---+--------------------+-----+
    Рассмотрим случайную величину ξ + Ω. Её возможные значения имеют
    вид  xn + yk,  где n, k ∈ N. Обозначим вероятность
        P(ξ = xn, Ω = yk) = p_nk
    Тогда
             ∞                  ∞
         Σ p_nk = pn   и    Σ p_nk = qk
            n=1                n=1
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                  Лектор рассказал почему это правда,
                  лень писать 😛
    Теперь докажем свойство:
.
            ∞   ∞
    M(ξ + Ω) =  Σ   Σ  (xn + yn) * p_nk =
           n=1 k=1
.
            ∞   ∞                ∞   ∞
         =  Σ   Σ  xn * p_nk  +  Σ   Σ  yn * p_nk   =
           n=1 k=1              n=1 k=1
.
            ∞     ∞          ∞     ∞
         =  Σ xn  Σ p_nk  +  Σ yn  Σ p_nk           =
           n=1   k=1        k=1   n=1
.
            ∞            ∞
         =  Σ xn pn  +   Σ yn qk                    = Mξ + MΩ
           n=1          k=1

**Следствие 1**
    Математическое ожидание суммы конечного числа случайных величин равно
    сумме их математических ожиданий.
              (  ∞     )       ∞
            M (  Σ ξ_k )   =   Σ Mξ_k
              ( n=1    )      n=1
**Доказательство**
    По индукции


**Свойство 4**
    Математическое ожидание произведения двух независимых случайных величин
    равно произведению их мат. ожиданий.
        M(ξ * Ω) = Mξ * MΩ

**Доказательство**
    Рассмотрим дискретные случайные величины ξ и Ω, заданные своими законами (или
    рядами, можно как угодно) распределения.
    Да, кстати, здесь везде вместо Ω должна быть `этта`
.
         +---+--------------------+-----+
         | ξ | x1 | x2 | ... | xn | ... |
         +------------------------+-----+
         | P | p1 | p2 | ... | pn | ... |
         +---+--------------------+-----+
.
         +---+--------------------+-----+
         | Ω | y1 | y2 | ... | yk | ... |
         +------------------------+-----+
         | P | q1 | q2 | ... | qk | ... |
         +---+--------------------+-----+
.
    Рассмотрим случайную величину ξ * Ω. Её возможные значения имеют
    вид  xn * yk,  где n, k ∈ N. Так как случайные величины ξ и Ω
    **независимы**. P(ξ = xn, Ω = yk)  =  P(ξ = xn) * P(Ω = yk) = pn qk
.
    Тогда
                         ∞   ∞
        M(ξΩ) =  Σ   Σ  (xn yk) * P(ξ = xn, Ω = yk)     =
                        n=1 k=1
                         ∞   ∞
              =  Σ   Σ  (xn yk) * pn * qk               =
                        n=1 k=1
                         ∞               ∞
              =  Σ xn * pn  *    Σ  yk * qk             =  Mξ * MΩ
                        n=1             k=1

**Следствие 2**
    Математическое ожидание произведения конечного числа попарно независимых
    случайных величин равно произведению их мат. ожиданий.
.
              (  ∞     )      ∞
        M (  П ξ_k )  =   П Mξ_k
              ( n=1    )     n=1
.
    Тут доказательство это не просто мат. индукция, но нам пофиг 😎


Пусть ξ -- некоторая случайная величина, φ(x) -- непрерывная числовая функция,
область определения которой содержит множество значений функции ξ. Тогда определена
сложная функция:
    φ(ξ): Ω → R
                 ^
                 +--- множество элементарных событий
    Очевидно, что φ(ξ) является случайной величиной
При сделанных предположениях справедливо следующее свойство:
**Свойство 5**
    1) Пусть ξ -- дискретная случайная величина, принимающая счетное множество
    значений  x1 x2 ... xn ...  с вероятностями  p1 p2 ... pn ...  Тогда
                   ∞
        M φ(ξ)  =  Σ φ(xn) pn
                  n=1
    Пусть ξ -- непрерывная случайная величина и p_ξ(x) -- её плотность
    распределения. Тогда:
                     ∞
        M φ(ξ)  = integrate φ(x) p_ξ(x) dx
                    -∞
    Без доказательства, ибо гроб ⚰️

На экзамене это будет делиться на два (??? я не понял)

**лекция 2024-11-05**

## Параграф 5. Дисперсия😞 и ее свойства
### 1. Определение и основная формула
Математическое ожидание характеризует среднее значение случайной величины. Однако возможные значения случайной величины могут сильно отличаться от среднего.
Рассмотрим две случайные величины
+----+--------------+
| ξ1 | -0.01 | 0.01 |
+----+--------------+
| P  |  0.5  | 0.5  |
+----+--------------+

+----+-------------+
| ξ2 | -100 |  100 |
+----+-------------+
| P  |  0.5 | 0.5  |
+----+-------------+

Поэтому вводится еще одна числовая характерстика, которая характеризует степень отклонения возможных значений от среднего.

**Опредленение 1**
    Дисперсией СВ ξ называется математическое ожидание квадрата отклонения СВ от ее математического ожидания
    Dξ = M( (ξ - Mξ)^2 )

**Теорема 1**
    Для любой СВ ξ справедливо равенство ✊
    Dξ = M(ξ^2) - (Mξ)^2  **(1)**
**Доказательство**
    По определению Dξ = M( (ξ - Mξ)^2 ) = M( ξ^2 - 2Mξ + (Mξ)^2 )
    Учитывая свойства мат ожидания, получим
    M(ξ^2) - 2 * Mξ * Mξ + M( (Mξ)^2 ) = M(ξ^2) - 2(Mξ)^2 + (Mξ)^2 = M(ξ^2) - (Mξ)^2
    **QED**

Используя свойство 5 из параграфа 4, запишем формулу для ξ^2 в случае дискретных и непрерывных величин
M(φ(ξ));    φ(x) = x^2
Пусть ξ -- дискретная СВ, принимающая счетное множество значений x1, ... x_n...
                                                 с вероятностями p1, ... p_n...
         ∞
M(ξ^2) = Σ x_n^2 p_n
        n=1
Пусть ξ -- непрерывная СВ и p_ξ(x)
             ∞
M(ξ^2) = integrate x^2 p_ξ(x) dx
            -∞

**Определение 2**
Средним квадратическим (квадратичным) отклонением СВ ξ называется корень квадратный из ее дисперсии.
Обозначается σ(ξ) = sqrt(Dξ)

### 2. Примеры вычисления дисперсии
#### Пример 1. Биномиальное распределение
Пусть СВ ξ распределена по биномиальному закону с параметрами n и p, *то есть производится n независимых испытаний, в каждом из которых вероятность наступления события A равна p, ξ -- число наступлений события A*

Можно доказать, что дисперсия вычисляется по формуле Dξ = npq
#### Пример 2. Распределение Пуассона
Пусть СВ ξ распределена по закону Пуассона с параметром λ. Возможные значения этой СВ🚆 0, 1 ... n
P(ξ=n) = λ^n / n! * e^-λ
В параграфе 4 было доказательство, что Mξ = λ. Найдем M(ξ^2)
         ∞                            ∞
M(ξ^2) = Σ n^2 λ^n / n! * e^-λ = e^-λ Σ n^2 λ^n / n! =
        n=0                          n=1
         ∞
  = e^-λ Σ n λ^n / (n-1)! = **|n-1 = k|** =
        n=1
         ∞                           ∞
  = e^-λ Σ k+1 λ^(k+1) / k! = λ e^-λ Σ k+1 λ^k / k! =
        k=0                         k=0
             ∞               ∞
  = λ e^-λ ( Σ k λ^k / k!  + Σ λ^k / k! ) = ... = **|k-1 = m|** =
            k=0             k=0 ___=e^λ___
              ∞
  = λ e^-λ (λ Σ λ^m / m! - e^λ) = λ^2 + λ
             m=0

Dξ = λ^2 + λ - λ^2 = λ
#### Пример 3
Пусть непрерывная СВ ξ :
         { 0, x < a
p_ξ(x) = { 1 / b-a, a <= x <= b
         { 0, x > b

В параграфе 4 Mξ = a+b / 2
Найдем M(ξ^2)
             ∞                     a           b               ∞
M(ξ^2) = integrate x^2 p_ξ(x) dx = ∫x^2 0 dx + ∫x^2 1/b-a dx + ∫x^2 0 dx =
            -∞                    -∞           a               b
  = ... = (a^2 + ab + b^2) / 3
Dξ = M(ξ^2) - (Mξ)^2 = (a^2 + ab + b^2) / 3 - (a + b)^2 / 4 = (b - a)^2 / 12
### 3. Свойства
1. Дисперсия любой СВ неотрицательна (очевидно)
    Так как (ξ - Mξ)^2 >= 0, то и M( (ξ - Mξ)^2 ) >= 0
2. Дисперсия постоянной равна нулю
    DC = 0
    **Доказательство**
        DC = M( (C - MC)^2 ) = M((C-C)^2) = M0 = 0
3. Постоянный множитель можно выносить за знак дисперсии, предварительно возведя его в квадрат
    D(Cξ) = C^2 Dξ
    **Доказательство**
        Используя формулу (1), получим
        D(Cξ) = M(Cξ)^2 - (M(Cξ))^2 = M(C^2ξ^2) - (CMξ)^2 = ... = C^2 Dξ
        **QED**
4. Для любых двух случайных величин ξ и η
    D(ξ ± η) = Dξ + Dη ± 2(M(ξη) - MξMη)
    **Доказательство**
        Используя формулу 1, получим
        D(ξ ± η) = M(ξ ± η)^2 - (M(ξ ± η))^2 = M(ξ^2 ± 2ξη + η^2) - (Mξ ± Mη)^2 =
          = M(ξ^2) ± 2m(ξη) + M(η^2) - (Mξ)^2 ∓ 2Mξ - (Mη)^2 = ... = Dξ + Dη ± 2( M(ξη) - Mξ Mη )
        **QED**
5. Если СВ ξ и η независимы, то
    D(ξ ± η) = Dξ + Dη
    **Доказательство**
        Так как СВ ξ и η -- независимы, то
        M(ξη) = Mξ Mη
    **Следствие**
        Дисперсия суммы конечного числа попарно независимых СВ равна сумме их дисперсий.
           n         n
        D( ∑ ξ_i ) = ∑ Dξ_i
          i=1       i=1

### 4. Моменты случайной величины
Кроме мат ожидания и дисперсии, для любой СВ можно определить и другие числовые характеристики, которые называются моментами.
**Определение 3**
Начальным моментом k-го порядка СВ ξ называется число α_k = M(ξ^k)
Центральным моментом k-го порядка называется число μ_k = M((ξ - Mξ)^k)
α_1 = Mξ, α_2 = M(ξ^2)
μ_1 = M(ξ - Mξ) = Mξ - M(Mξ) = Mξ - Mξ = 0
μ_2 = M((ξ - Mξ)^2) = Dξ
Формула принимает вид
μ_2 = α_2 - α_1^2

## Параграф 6. Нормальное распределение🔔 и его свойства
**Определение 1**
Распределение СВ ξ называется нормальным, если его плотность задается формулой
p_ξ(x) = 1 / σ√2π e^( -(x-a)^2 / (2 σ^2) )
где a ∈ R

Если ξ -- нормально распределенная СВ с параметрами a и σ, то это иногда записывают вот так:
ξ ~ *N*(a, b)

## Параграф 7
*Своровать конспект у Дани, пока он отвернулся*

*лекция 2024-11-19*

## Параграф 8 Закон больших чисел
Под законом больших чисел понимают совокупность теорем, в которых на последовательность случайных величин налагают некоторые условия при выполнении которых среднее арифметическое этих случайных величин сходится по вероятности к среднему арифметическому их математических ожиданий.
**Теорема 1. Неравенсто Чебышева**
    Пусть ξ -- СВ, имеющая конечную дисперсию. Тогда для любого ε > 0 выполнятся неравенство
    (1) P(|ξ - Mξ| >= ε) <= Dξ / ε^2
**Доказательство**
    Доказательство проведем для непрерывной СВ ξ, плотностью распределения которой является функция p_ξ(x)
    vvvvvvvvvvvvv                      vvvvvvvvvvvvvvvvvvvvvvvvvv
    ------------|-----------|----------|------------------------->
              Mξ - ε       Mξ      Mξ + ε
    P(|ξ - Mξ| >= ε) = P(ξ <= Mξ - ε или ξ >= Mξ + ε) = P(ξ <= Mξ - ε) + P(ξ >= Mξ + ε) **=**
    Учитывая свойства непрерывной СВ, получаем
         Mξ-ε          ∞
    **=** ∫ p_ξ(x)dx + ∫ p_ξ(x)dx **=**
         -∞           Mξ+ε
    ,
    Заштрихованное множество -- это множество точек
    {x ∈ *R* : |x - Mξ| >= ε}
    ,
    **=** ∫ p_ξ(x)dx = ∫ **1** * p_ξ(x) dx **<=**
        |x-Mξ|>=ε     |x-Mξ|>=ε
    ,
    Так как |x-Mξ|>=ε, то |x-Mξ| / ε >= 1 → (x - Mξ)^2 / ε^2 >= 1
                                             +∞
    **<=**  ∫|x-Mξ| / ε^2 p_ξ(x)dx <= 1 / ε^2 ∫ (x - Mξ)^2 p_ξ(x) dx **=**
        |x-Mξ|>=ε                            -∞
                  +∞                     +∞                     +∞
    **=** 1 / ε^2 (∫x^2 p_ξ(x) dx) - 2 Mξ ∫ x p_ξ(x) dx + (Mξ)^2 ∫ p_ξ(x) dx) **=**
                  -∞                     -∞                     -∞
    **=** ... = 1 / ε^2 * Dξ
    **QED**
**Следствие 1**
    Пусть ξ -- СВ, имеющая конечную дисперсию. Тогда для любого ε > 0 выполнятся неравенство
    (2) P(|ξ - Mξ| < ε) >= 1 - Dξ / ε^2
**Доказательство**
    Так как события |ξ - Mξ| >= ε и |ξ - Mξ| < ε, являются противоположными,то
    P(|ξ - Mξ| < ε) = 1 - P(|ξ - Mξ| >= ε) = 1 - Dξ / ε^2
    **QED**

**Теорема 2. Теорема Чебышева**
    Пусть {ξ_k}:k=1..∞ -- последовательность попарно независмых СВ, причем их дисперсии ограничены в совокупности, то есть существует c > 0: Dξ_k <= C для любого k ∈ *N*
    Тогда для любого ε > 0 выполняется равенство
            ξ1 + ... + ξ_n     Mξ1 + ... + Mξ_n
     lim P(---------------- - ------------------ < ε) = 1 (3)
     n->∞         n                    n
**Доказательство**
                             n
    Рассмотрим 👀 СВ ξ = 1/n ∑ ξ_k и найдем ее мат ожидание и дисперсию:
                            k=1
               n              n            n
    Mξ = M(1/n ∑ ξ_k) = 1/n M(∑ ξ_k) = 1/n ∑ Mξ_k (Сл 1 параграф 4)
              k=1            k=1          k=1
               n                n
    Dξ = D(1/n ∑ ξ_k) = 1 / n^2 ∑ Dξ_k (Сл 1 параграф 5)
              k=1              k=1
    ,
    P(|ξ - Mξ| > ε) <= 1 - Dξ / ε^2
    ,
           n           n                               n
    P(|1/n ∑ ξ_k - 1/n ∑ Mξ_k| < ε) >= 1 - 1 / ε^2 n^2 ∑ Dξ_k >= 1 - C / (ε^2 n)
          k=1         k=1                             k=1
    Итак,
           n           n
    P(|1/n ∑ ξ_k - 1/n ∑ Mξ_k| < ε) >= 1 - C / (ε^2 n)
          k=1         k=1
    Переходя в этом неравенстве к пределу, получим
               n           n
    lim P(|1/n ∑ ξ_k - 1/n ∑ Mξ_k| < ε) >= 1 (так как 1 - C / (ε^2 n) -> 0)
    n->∞      k=1         k=1                                        n->∞
    **QED**

Замечение: При достаточно больших значениях n выполняется приближенное равенство
        ξ1 + ... + ξ_n     Mξ1 + ... + Mξ_n
    P(---------------- = ------------------) ~= 1
            n                    n
### Пример
Завод производит n товаров
ξ_k -- доход от продажи k-го товара
Хочется посчитать средний доход
     ξ1 + ... + ξ_n
ξ = ---------------- -- средний доход
           n
Mξ_k -- средний доход от реализации k-го товара (известно)
 Mξ1 + ... + Mξ_n
------------------ ;
        n

**Теорема 3. Теорема Пуассона**
    Пусть производится последовательность независимых испытаний, причем вероятность наступления события A в k-ом испытании равна P_k. Пусть m -- число наступлений события A в n испытаниях.
    ,
    Тогда для любого ε > 0 выполняется равенство
                    p1 + ... + p_n
    lim P(| m/n - ----------------- | < ε) = 1
    n->∞                  n
**Доказательство**
    Рассмотрим СВ ξ_k -- число наступлений события A в k-ом испытании. Тогда
    m = ξ1 + ... + ξ_n
    Закон распределения СВ ξ_k имеет вид
    ξ_k |  0  |  1  |
    ----+-----+-----+
     P  | q_k | p_k |
    Mξ_k = 0 * q_k + 1 * p_k = p_k
    M(ξ_k)^2 = 0^2 * q_k + 1^2 * p_k = p_k
    Dξ_k = p_k - p_k^2 = p_k q_k
    `
    Заметим, что x(1 - x) <= 1/4 для любого x ∈ (0, 1)
    (проверить самостоятельно)
    `
    Тогда
    Dξ_k - p_k q_k <= 1/4
    для любого k ∈ *N*
    ,
    Таким образом, для последовательности СВ {ξ_k}:k=1..∞ выполнены все условия теоремы Чебышева.
            ξ1 + ... + ξ_n     Mξ1 + ... + Mξ_n
     lim P(---------------- - ------------------ < ε) = 1
     n->∞         n                    n
                  Mξ1 + ... + Mξ_n
     lim P(m/n - ------------------ < ε) = 1
     n->∞                n
    **QED**

**Теорема 4. Теорема Бернулли**
    Пусть производится последовательность независимых испытаний, в каждом из которых вероятность наступления события A равна p
    И пусть m -- число наступления события A в n испытаниях.
    Тогда для любого ε > 0 выполняется равенство
        lim P(|m/n - p| < ε) = 1 (5)
        n->∞
**Доказательство**
    (4), где p1 = p2 = ... = p_n = p
                   p1 + ... + p_n
    Тогда m / n - ---------------- = m/n - np / n = m/n - p
                         n
    **QED**

**Теорема 5. Теорема Маркова**
    Пусть {ξ_k}:1..∞ -- это последовательность СВ, удовлетворяющих условию
                     n
     (6) lim 1/n^2 D(∑ ξ_k) = 0
         n->∞       k=1
    Тогда для любого ε > 0 выполняется равенство (3)
**Доказательство**
    Рассуждая *точно* так же, как при доказательстве *Теоремы Чебышева*, приходи к неравенству
               n           n                                  n
        P(|1/n ∑ ξ_k - 1/n ∑ Mξ_k| < ε) >= 1 - 1 / ε^2 n^2 D( ∑ ξ_k)
              k=1         k=1                                k=1
               n           n
    lim P(|1/n ∑ ξ_k - 1/n ∑ Mξ_k| < ε) >= 1
    n->∞      k=1         k=1
    Получилась формула (3)
    **QED**

*Лекция 2024-11-26*
## Параграф 9. Понятие о центральной предельной теореме
СВ ξ и η называются одинаково распределенными, если F_ξ(x) = F_η(x)
Если ξ и η одинаково распределены, то Mξ = Mη и Dξ = Dη

**Теорема 1**
    Пусть {ξ_k},k=1..∞ -- последовательность независимых и одинаково распределенных СВ, причем Mξ_k = μ и Dξ_k = σ^2. Тогда для любого x ∈ *R* выполняется равенство:
            n                                     x
    lim P( (∑ξ_k - μn) / (σ √n) < x ) = (1 / √2π) ∫ e^(- t^2 / 2) dt
    n->∞   k=1                                   -∞
**Без доказательства**
                                       n
При достаточно больших значениях n P( (∑ξ_k - μn) / (σ √n) < x ) ~=
                                      k=1
             x
~= (1 / √2π) ∫ e^(- t^2 / 2) dt = F_{N(0, 1)}(x)
            -∞
{ξ_k}
    n
ξ = ∑ ξ_k
   k=1
                       n               n
F_ξ(x) = P(ξ < x) = P( ∑ ξ_k < x) = P( ∑ ξ_k - μn < x + μn) =
                      k=1             k=1
        n
        ∑ ξ_k - μn
       k=1                 x - μ
= P( ---------------- < ------------ ) ~=
         σ√n                σ√n
,
    x-μn / σ√n
~= 1/√2π ∫ e^(- t^2 / 2) dt = ... = F_{N(μn, σ√n)}(x)
        -∞
 n
 ∑ ξ_k (где n велико) приближенно имеет нормальный закон распределения
k=1
, где μn и σ√n -- параметры
Формула, которую мы получили, является суммой большого числа независимых и одинаково распределенных случайных величин
# Раздел 3. Элементы мат статистики
## Параграф 1. Статистическое распределение выборки
Предположим, что имеется некоторая совокупность однородных объектов, которые нужно изучить относительно какого-то количественного признака. Значения этого признака задают некоторую СВ ξ.
Часто бывает, что вся совокупность возможных значений СВ ξ неизвестна. И для того, чтобы найти функцию распределения этой СВ делают выборку нескольких ее значений.

Например, для деталей контролируемый признак -- диаметр гайки🔩
**Определение 1**
    *Выборкой объема n* для данной СВ ξ называется совокупность x1 ... x_n независимых наблюдаемых значений этой СВ
Совокупность всех возможных значений СВ ξ, из которой производится выборка, называется **генеральной совокупностью**

Пусть имеется выборка объема n. Причем значение x1 наблюдалось n1 раз
x2 -- n2 раз
...
x_k -- n_k раз
Причем n1 + ... + n_k = n
Значения x1, ... x_k называются вариантами👩. Совокупность вариант👩, расположенных в порядке возрастания, называется **вариационным рядом**. Числа n1, ... n_k называются частотами.
Число w_i = n_i / n называется относительной частотой варианты x_i
Понятно, что w1 + ... + w_k = 1
**Определение 2**
    *Статистическим распределением выборки* называется перечень ее вариант👩, расположенных в порядке возрастания, и соответствующих им частот или относительных частот.
Иногда строится интервальное статистическое распределение. Для этого интервал, содержащий все варианты, разбивают на k равных интервалов. На практике k обычно берется от 9-10 до 20-25
Частотой i-го интервала называют сумму частот вариант👩, попавших в этот интервал.

**Интервальным статистическим распределением** называют перечень интервалов, расположенных в порядке возрастания и соответствующих им частот или относительных частот

_Остаток параграфа списать у Вани_

## Параграф 2. Полигон и гистограмма
Чобы наглядно представить статистическое распределение выборки, строят различные графики, среди которых -- полигон и гистограмма.
Пусть задано статистическое распределение выборки объеме n.
x_i | x1 | ... | x_k |                                
----+----+-----+-----+
n_i | n1 | ... | n_k |                             

**Определение 1**
    Полигоном частот (относительных частот) называется ломаная, соединяющая точки (x1, n1), (x2, n2), ... (x_k, n_k) *( или точки (x1, w1), (x2, w2), ... (x_k, w_k) )*

Рисунок полигона:
*Я НЕ БУДУ ЭТО РИСОВАТЬ Я НЕ БУДУ ЭТО РИСОВАТЬ Я НЕ БУДУ ЭТО РИСОВАТЬ Я НЕ БУДУ ЭТО РИСОВАТЬ Я НЕ БУДУ ЭТО РИСОВАТЬ НЕ БУДУ ЭТО РИСОВАТЬ Я НЕ БУДУ ЭТО РИСОВАТЬ*

Полигон обычно строят, если СВ ξ является дискретной. Если же она является непрерывной, то лучше построить гистограмму частот или относительных частот. Для этого интервал, содержащий все варианты, разбивают на равные интервалы длины h
**Определение 2**
    Гистограммой частот (относительных частот) называется ступенчатая фигура, представляющая собой объединение конечного числа прямоугольников, основаниями которых служат интервалы длины h, а высота i-го прямоугольника равна n_i/h (w_i/h)

Площадь гистограммы частот равна объему выборки n.
    m       m
S = ∑ S_i = ∑ h n_i / h = n
   i=1     i=1
, где n_i -- частота i-го интервала, то есть сумма частот тех вариант👩, которые попали в этот интервал.

Аналогично проверяется, что площадь гистограммы относительных частот равна единице.

### Пример
интервал | 0-5 | 5-10 | 10-15 |
---------+-----+------+-------+
частоты  | 20  |  50  |  30   |
---------+-----+------+-------+
n_i / h  |  4  |  10  |   6   |

📊

## Параграф 3. Эмпирическая функция распределения
Пусть ξ -- некоторая СВ. Предположим, что для этой СВ имеется выборка объема n. Статистическое распределение которой приведено в таблице
x_i | x1 | ... | x_k |
----+----+-----+-----+
n_i | n1 | ... | n_k |

Число вариант, меньше x. С учетом их частот.
A = {ξ < x}
**Определение 1**
    Эмпирической функцией распределения СВ ξ называется функция F*_ξ(x) : x ∈ *R*,
    F*_ξ(x) = n_x / n

Обычная функция распределения, которую мы изучили ранее, будем называть теоретической функцией распределения. Теоретическая функция распределения каждому x ∈ *R* ставит соответствие *вероятность* события {ξ < x}, а эмпирическая функция распределения -- *относительную* частоту этого события

Применяя к событию A = {ξ < x} теорему Бернулли, получаем
lim P(|F*_ξ(x) - F_ξ(x)| < ε) = 1
n->∞
